{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f79226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Suppress TensorFlow logs\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Suppress all but fatal errors\n",
    "\n",
    "# Optional: Disable oneDNN info message\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "# Optional: Disable XLA to reduce cu* factory warnings\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e88543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 18:18:31.189963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754435911.204641   77526 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754435911.208554   77526 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754435911.218658   77526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754435911.218681   77526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754435911.218683   77526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754435911.218684   77526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "E0000 00:00:1754435913.446241   77526 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1754435913.447557   77526 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/isaac/anaconda3/envs/TFCoil/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-05 18:18:33,979\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "tf.constant(1.0)  # Trigger basic op\n",
    "import logging\n",
    "logging.getLogger('absl').setLevel(logging.ERROR)\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from surface_coil_loader import load_full_dataset, load_split_datasets\n",
    "from transformers_copy import TransformerEncoder, TransformerDecoder\n",
    "from CoilAutoencoder_copy import CoilAutoencoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b23326",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_dir = Path(\"mini_surface_coil_tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80623650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coil_autoencoder(hp):\n",
    "    encoder = TransformerEncoder(max_sets=6, features_per_set=100, name='coil', embed_dim=hp[\"embed_dim\"],\n",
    "        num_heads=hp[\"num_heads\"], ff_dim=hp[\"ff_dim\"], \n",
    "        num_sab_blocks=hp[\"sab_blocks\"], dropout=hp[\"enc_dropout\"])\n",
    "    \n",
    "    decoder = TransformerDecoder(name = 'coil', embed_dim=hp[\"embed_dim\"], num_heads=hp[\"num_heads\"], ff_dim=hp[\"ff_dim\"],\n",
    "        num_layers=hp[\"decoder_blocks\"], max_sets=6, features_per_set=100, dropout=hp[\"dec_dropout\"])\n",
    "    \n",
    "    autoencoder = CoilAutoencoderModel(encoder, decoder)\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52336c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperparams():\n",
    "    return {\n",
    "        'batch_size': np.random.choice([64, 128, 256]),\n",
    "        \"embed_dim\": np.random.choice([64, 128, 256]),\n",
    "        \"num_heads\": np.random.choice([4, 8]),\n",
    "        \"ff_dim\": np.random.choice([128, 256, 512]),\n",
    "        \"enc_dropout\": np.random.uniform(0.0, 0.3),\n",
    "        \"dec_dropout\": np.random.uniform(0.0, 0.3),\n",
    "        \"learning_rate\": 10 ** np.random.uniform(-5, np.log10(3)-3),\n",
    "        'weight_decay': 10 ** np.random.uniform(np.log10(5)-3, -2),\n",
    "        'sab_blocks': np.random.choice([1,2,3,4,5,6]),\n",
    "        'decoder_blocks': np.random.choice([1,2,3,4,5,6])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a04ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model, _, _ = build_coil_autoencoder(hp)    \n",
    "    optimizer = tf.keras.optimizers.Lion(learning_rate=hp['learning_rate'], weight_decay=hp['weight_decay'])\n",
    "    model.compile(optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00b5e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trial(hp, train_dataset, val_dataset, trial_id=0, epochs=10, use_wandb=False):\n",
    "    callbacks = []\n",
    "    model = build_model(hp)\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    tb_logdir = f\"logs/trial_{trial_id}\"\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=tb_logdir))\n",
    "\n",
    "    # Optional: wandb logging\n",
    "    if use_wandb:\n",
    "        import wandb\n",
    "        from wandb.keras import WandbCallback\n",
    "        wandb.init(project=\"coil_autoencoder\", config=hp, name=f\"trial_{trial_id}\")\n",
    "        callbacks.append(WandbCallback())\n",
    "        #attn_map = attn_weights[0].numpy()  # (num_queries, encoded_len)\n",
    "        #wandb.log({\"attention_heatmap\": wandb.Image(attn_map)})\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    val_loss = model.evaluate(val_dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42fda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=0)  # Set num_gpus=0 if you want CPU-only runs\n",
    "def parallel_train_trial(hp, trial_id, use_wandb):\n",
    "    train, val, test = load_split_datasets(\n",
    "        tfrecord_dir, batch_size=hp['batch_size'], train_frac=0.9, val_frac=0.1\n",
    "    )\n",
    "    val_loss = train_trial(hp, train, val, trial_id, use_wandb=use_wandb)\n",
    "    return val_loss, hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b317fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search_parallel(n_trials=10, use_wandb=False):\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    result_refs = []\n",
    "    for trial_id in range(n_trials):\n",
    "        hp = sample_hyperparams()\n",
    "        ref = parallel_train_trial.remote(hp, trial_id, use_wandb)\n",
    "        result_refs.append(ref)\n",
    "\n",
    "    results = ray.get(result_refs)  # This blocks until all trials are done\n",
    "\n",
    "    # Sort by val_loss\n",
    "    results.sort(key=lambda x: x[0][0])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7877979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_search(n_trials=10, use_wandb=True, save_dir=\"saved_models\"):\n",
    "    results = []\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for trial_id in range(n_trials):\n",
    "        hp = sample_hyperparams()\n",
    "        train, val, test = load_split_datasets(tfrecord_dir, batch_size=hp['batch_size'], train_frac=0.9)\n",
    "        val_loss = train_trial(hp, train, val, trial_id, use_wandb=use_wandb)\n",
    "        save_path = os.path.join(save_dir, f\"trial_{trial_id:03d}_val_{val_loss[0]:.4f}\")\n",
    "        #model.save(save_path)\n",
    "        results.append((val_loss, hp, save_path))\n",
    "\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e02bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f065006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/TFCoil/lib/python3.9/site-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 7, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/TFCoil/lib/python3.9/site-packages/keras/src/models/functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: {'coil_data': 'coil_data', 'coil_mask': 'coil_mask'}\n",
      "Received: inputs={'coil_data': 'Tensor(shape=(None, None, 100))', 'coil_mask': 'Tensor(shape=(None, None))', 'surface_data': 'Tensor(shape=(None, None, 4))', 'surface_mask': 'Tensor(shape=(None, None))'}\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     43/Unknown \u001b[1m13s\u001b[0m 129ms/step - coil_loss: 0.2087 - loss: 1.1691 - mae: 0.2569 - scaler_loss: 0.9604 - unmasked_mse: 0.4729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/TFCoil/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - coil_loss: 0.2076 - loss: 1.1465 - mae: 0.2543 - scaler_loss: 0.9389 - unmasked_mse: 0.4710 - val_coil_loss: 0.1802 - val_loss: 0.1845 - val_mae: 0.1294 - val_scaler_loss: 0.0043 - val_unmasked_mse: 0.3920\n",
      "Epoch 2/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - coil_loss: 0.1721 - loss: 0.1781 - mae: 0.1406 - scaler_loss: 0.0060 - unmasked_mse: 0.3844 - val_coil_loss: 0.1761 - val_loss: 0.1763 - val_mae: 0.1273 - val_scaler_loss: 1.9236e-04 - val_unmasked_mse: 0.3779\n",
      "Epoch 3/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - coil_loss: 0.1725 - loss: 0.1782 - mae: 0.1513 - scaler_loss: 0.0056 - unmasked_mse: 0.3851 - val_coil_loss: 0.1797 - val_loss: 0.1809 - val_mae: 0.1494 - val_scaler_loss: 0.0013 - val_unmasked_mse: 0.3867\n",
      "Epoch 4/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 124ms/step - coil_loss: 0.1714 - loss: 0.1842 - mae: 0.1571 - scaler_loss: 0.0128 - unmasked_mse: 0.3865 - val_coil_loss: 0.1703 - val_loss: 0.1922 - val_mae: 0.1552 - val_scaler_loss: 0.0219 - val_unmasked_mse: 0.3663\n",
      "Epoch 5/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - coil_loss: 0.1731 - loss: 0.1893 - mae: 0.1560 - scaler_loss: 0.0163 - unmasked_mse: 0.3851 - val_coil_loss: 0.1828 - val_loss: 0.1888 - val_mae: 0.1612 - val_scaler_loss: 0.0060 - val_unmasked_mse: 0.3954\n",
      "Epoch 6/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - coil_loss: 0.1735 - loss: 0.1899 - mae: 0.1547 - scaler_loss: 0.0164 - unmasked_mse: 0.3856 - val_coil_loss: 0.1698 - val_loss: 0.1925 - val_mae: 0.1533 - val_scaler_loss: 0.0227 - val_unmasked_mse: 0.3652\n",
      "Epoch 7/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 123ms/step - coil_loss: 0.1735 - loss: 0.1900 - mae: 0.1541 - scaler_loss: 0.0165 - unmasked_mse: 0.3845 - val_coil_loss: 0.1829 - val_loss: 0.1904 - val_mae: 0.1498 - val_scaler_loss: 0.0076 - val_unmasked_mse: 0.3916\n",
      "Epoch 8/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - coil_loss: 0.1733 - loss: 0.1884 - mae: 0.1530 - scaler_loss: 0.0151 - unmasked_mse: 0.3854 - val_coil_loss: 0.1705 - val_loss: 0.1923 - val_mae: 0.1524 - val_scaler_loss: 0.0217 - val_unmasked_mse: 0.3665\n",
      "Epoch 9/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - coil_loss: 0.1706 - loss: 0.1862 - mae: 0.1511 - scaler_loss: 0.0156 - unmasked_mse: 0.3834 - val_coil_loss: 0.1829 - val_loss: 0.1897 - val_mae: 0.1563 - val_scaler_loss: 0.0068 - val_unmasked_mse: 0.3959\n",
      "Epoch 10/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - coil_loss: 0.1714 - loss: 0.1860 - mae: 0.1487 - scaler_loss: 0.0146 - unmasked_mse: 0.3845 - val_coil_loss: 0.1699 - val_loss: 0.1905 - val_mae: 0.1479 - val_scaler_loss: 0.0205 - val_unmasked_mse: 0.3667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - coil_loss: 0.1721 - loss: 0.1926 - mae: 0.1476 - scaler_loss: 0.0205 - unmasked_mse: 0.3685\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 804ms/step - coil_loss: 0.3799 - loss: 7.0388 - mae: 0.6994 - scaler_loss: 6.6589 - unmasked_mse: 0.8464 - val_coil_loss: 0.4247 - val_loss: 0.4295 - val_mae: 0.6590 - val_scaler_loss: 0.0048 - val_unmasked_mse: 0.9313\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 584ms/step - coil_loss: 0.3946 - loss: 0.5797 - mae: 0.6541 - scaler_loss: 0.1851 - unmasked_mse: 0.9005 - val_coil_loss: 0.4068 - val_loss: 0.6090 - val_mae: 0.5968 - val_scaler_loss: 0.2022 - val_unmasked_mse: 0.8932\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 709ms/step - coil_loss: 0.3761 - loss: 0.4007 - mae: 0.6033 - scaler_loss: 0.0246 - unmasked_mse: 0.8518 - val_coil_loss: 0.3692 - val_loss: 0.5027 - val_mae: 0.5568 - val_scaler_loss: 0.1335 - val_unmasked_mse: 0.8091\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 698ms/step - coil_loss: 0.3381 - loss: 0.3554 - mae: 0.5626 - scaler_loss: 0.0173 - unmasked_mse: 0.7721 - val_coil_loss: 0.3326 - val_loss: 0.3600 - val_mae: 0.5241 - val_scaler_loss: 0.0274 - val_unmasked_mse: 0.7278\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 700ms/step - coil_loss: 0.3091 - loss: 0.3242 - mae: 0.5218 - scaler_loss: 0.0150 - unmasked_mse: 0.7029 - val_coil_loss: 0.3035 - val_loss: 0.3221 - val_mae: 0.4795 - val_scaler_loss: 0.0186 - val_unmasked_mse: 0.6630\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 579ms/step - coil_loss: 0.2847 - loss: 0.2959 - mae: 0.4773 - scaler_loss: 0.0112 - unmasked_mse: 0.6428 - val_coil_loss: 0.2774 - val_loss: 0.2920 - val_mae: 0.4344 - val_scaler_loss: 0.0146 - val_unmasked_mse: 0.6051\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 741ms/step - coil_loss: 0.2611 - loss: 0.2715 - mae: 0.4350 - scaler_loss: 0.0104 - unmasked_mse: 0.5902 - val_coil_loss: 0.2561 - val_loss: 0.2669 - val_mae: 0.3923 - val_scaler_loss: 0.0109 - val_unmasked_mse: 0.5579\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 767ms/step - coil_loss: 0.2432 - loss: 0.2539 - mae: 0.3990 - scaler_loss: 0.0107 - unmasked_mse: 0.5493 - val_coil_loss: 0.2400 - val_loss: 0.2487 - val_mae: 0.3596 - val_scaler_loss: 0.0087 - val_unmasked_mse: 0.5226\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 584ms/step - coil_loss: 0.2294 - loss: 0.2391 - mae: 0.3680 - scaler_loss: 0.0097 - unmasked_mse: 0.5170 - val_coil_loss: 0.2267 - val_loss: 0.2311 - val_mae: 0.3282 - val_scaler_loss: 0.0044 - val_unmasked_mse: 0.4935\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 687ms/step - coil_loss: 0.2180 - loss: 0.2279 - mae: 0.3396 - scaler_loss: 0.0099 - unmasked_mse: 0.4921 - val_coil_loss: 0.2172 - val_loss: 0.2216 - val_mae: 0.2977 - val_scaler_loss: 0.0045 - val_unmasked_mse: 0.4726\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - coil_loss: 0.2117 - loss: 0.2162 - mae: 0.2978 - scaler_loss: 0.0045 - unmasked_mse: 0.4721\n"
     ]
    }
   ],
   "source": [
    "res = run_random_search(n_trials=2, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8213500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([<tf.Tensor: shape=(), dtype=float32, numpy=0.17599551379680634>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.1227232962846756>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.3796854019165039>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.05327221378684044>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.27929821610450745>],\n",
       "  {'batch_size': 128,\n",
       "   'embed_dim': 256,\n",
       "   'num_heads': 4,\n",
       "   'ff_dim': 256,\n",
       "   'enc_dropout': 0.2549885360880258,\n",
       "   'dec_dropout': 0.04841201638431631,\n",
       "   'learning_rate': 2.759230028803988e-05,\n",
       "   'weight_decay': 0.007528391760608386,\n",
       "   'sab_blocks': 1,\n",
       "   'decoder_blocks': 6},\n",
       "  'saved_models/trial_001_val_0.1760'),\n",
       " ([<tf.Tensor: shape=(), dtype=float32, numpy=0.24534067511558533>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.1677953153848648>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.29536762833595276>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.07754535228013992>,\n",
       "   <tf.Tensor: shape=(), dtype=float32, numpy=0.4115840196609497>],\n",
       "  {'batch_size': 256,\n",
       "   'embed_dim': 128,\n",
       "   'num_heads': 8,\n",
       "   'ff_dim': 128,\n",
       "   'enc_dropout': 0.0021343825688296403,\n",
       "   'dec_dropout': 0.10754474709054757,\n",
       "   'learning_rate': 2.9045073108541713e-05,\n",
       "   'weight_decay': 0.005256085971188301,\n",
       "   'sab_blocks': 4,\n",
       "   'decoder_blocks': 2},\n",
       "  'saved_models/trial_000_val_0.2453')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4734b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf25bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda3/envs/TFCoil/lib/python3.9/site-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 7, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hp = sample_hyperparams()\n",
    "model = build_model(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc0f74f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "dataset = load_coil_dataset(tfrecord_dir, batch_size=64)\n",
    "for input, _ in dataset.take(1):\n",
    "    output = model(inputs = {'coil_data': input['coil_data'], 'coil_mask': input['coil_mask']})  # output: (B, N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "638e38f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'coil_data': TensorSpec(shape=(None, 7, 100), dtype=tf.float32, name=None), 'coil_mask': TensorSpec(shape=(None, 6), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 6, 100), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.take(1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd1b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cee4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_trials = sorted(results, key=lambda x: x[0])[:20]  # val_loss ascending\n",
    "top_configs = [dict(config) for _, config, _ in top_trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faffd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_loss\",\n",
    "        \"goal\": \"minimize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"embed_dim\": {\"values\": [64, 128, 256]},\n",
    "        \"num_heads\": {\"values\": [4, 6, 8]},\n",
    "        \"ff_dim\": {\"values\": [128, 256, 512]},\n",
    "        \"dropout\": {\"min\": 0.0, \"max\": 0.3},\n",
    "        \"learning_rate\": {\"distribution\": \"log_uniform_values\", \"min\": 1e-4, \"max\": 1e-3}\n",
    "    },\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 5},\n",
    "    \"initial_points\": top_configs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe149978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train_fn():\n",
    "    import wandb\n",
    "    from wandb.keras import WandbCallback\n",
    "\n",
    "    wandb.init(project=\"coil_autoencoder\")\n",
    "    config = wandb.config\n",
    "\n",
    "    hp = dict(\n",
    "        embed_dim=config.embed_dim,\n",
    "        num_heads=config.num_heads,\n",
    "        ff_dim=config.ff_dim,\n",
    "        dropout=config.dropout,\n",
    "        learning_rate=config.learning_rate\n",
    "    )\n",
    "\n",
    "    model = build_coil_autoencoder(\n",
    "        embed_dim=hp[\"embed_dim\"],\n",
    "        num_heads=hp[\"num_heads\"],\n",
    "        ff_dim=hp[\"ff_dim\"],\n",
    "        max_coils=6,\n",
    "        features_per_coil=100,\n",
    "        dropout=hp[\"dropout\"]\n",
    "    )\n",
    "    model.compile(optimizer= tf.keras.optimizers.Lion(hp[\"learning_rate\"]))\n",
    "\n",
    "    callbacks = [WandbCallback()]\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=callbacks)\n",
    "\n",
    "    val_loss = model.evaluate(val_ds)\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "    # Save model\n",
    "    model.save(f\"saved_models/wandb_trial_{wandb.run.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(bayesian_sweep_config, project=\"coil_autoencoder\")\n",
    "wandb.agent(sweep_id, function=sweep_train_fn, count=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa63f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9df22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a4aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize learned queries\n",
    "def plot_learned_queries(model, layer_name=\"learned_query_decoder\"):\n",
    "    decoder_layer = model.get_layer(layer_name)\n",
    "    queries = decoder_layer.learned_queries.numpy()  # shape (N, D)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(queries, cmap=\"viridis\", cbar=True)\n",
    "    plt.xlabel(\"Embedding Dimension\")\n",
    "    plt.ylabel(\"Query Index\")\n",
    "    plt.title(\"Learned Queries (Coil Decoder)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out, attn_scores = self.attn(queries, encoded_set, return_attention_scores=True)\n",
    "\n",
    "def visualize_attention(attn_scores, query_idx=0):\n",
    "    \"\"\"\n",
    "    attn_scores: shape (B, num_queries, seq_len)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.heatmap(attn_scores[0, query_idx], cmap=\"magma\")\n",
    "    plt.title(f\"Attention Weights for Query {query_idx}\")\n",
    "    plt.xlabel(\"Encoded Coil Index\")\n",
    "    plt.ylabel(\"Head\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFCoil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
