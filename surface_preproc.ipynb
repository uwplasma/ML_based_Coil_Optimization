{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0672c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 23:21:25.730297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-27 23:21:25.744913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-27 23:21:25.749072: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simsopt.field import Current\n",
    "from simsopt.geo import SurfaceRZFourier\n",
    "from simsopt._core import load\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('quasr_simsopt_files')\n",
    "output_surface_dir = Path('surface_tfrecords')\n",
    "\n",
    "MAX_COEFS = 441\n",
    "MAX_NFP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c98d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value.flatten()))\n",
    "\n",
    "def _int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def serialize_surface(id: str, surface: np.ndarray, surface_mask: np.ndarray):\n",
    "    feature = {\n",
    "        'ID': _bytes_feature(id.encode('utf-8')),\n",
    "        'surface_data': _float_feature(surface),\n",
    "        'surface_mask': _int_feature(surface_mask)\n",
    "    }\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001feab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_surface(file_path):\n",
    "    \"\"\"\n",
    "    Convert s.x and metadata to [N_modes, 5] array:\n",
    "    columns = [m_norm, n_norm, is_cos, is_R, coeff_value]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        id = str(file_path)[-12:-5]\n",
    "        surfaces, coils = load(str(file_path))\n",
    "        outer_surface = surfaces[-1]\n",
    "        s = outer_surface.to_RZFourier() #the bottleneck in speed\n",
    "\n",
    "        x = s.x  # the coeff vector\n",
    "        nfp = s.nfp\n",
    "\n",
    "        num_coefs = len(x)\n",
    "        if num_coefs > MAX_COEFS:\n",
    "            print(num_coefs)\n",
    "        \n",
    "        m = s.m  # mode numbers, shape (N_modes,)\n",
    "        n = s.n\n",
    "        \n",
    "        num_modes = (len(m)+1)//2\n",
    "        # Normalize mode indices\n",
    "        max_m = np.max(np.abs(m)) or 1\n",
    "        max_n = np.max(np.abs(n)) or 1\n",
    "\n",
    "        # Type flags\n",
    "        is_cos = np.concatenate([\n",
    "            np.ones(num_modes, dtype=bool),  # R_cos\n",
    "            np.zeros(num_modes-1, dtype=bool)  # Z_sin\n",
    "        ])\n",
    "\n",
    "        surface_set = np.zeros((MAX_COEFS, 5), dtype=np.float32)\n",
    "        surface_mask = np.zeros((MAX_COEFS,), dtype=np.int64)\n",
    "        nfp_norm = float(nfp) / MAX_NFP \n",
    "\n",
    "        for i in range(min(num_coefs, MAX_COEFS)):\n",
    "            surface_set[i] = [\n",
    "                m[i] / max_m,\n",
    "                n[i] / max_n,\n",
    "                float(is_cos[i]),\n",
    "                x[i],\n",
    "                nfp_norm\n",
    "            ]\n",
    "            surface_mask[i] = 1\n",
    "            \n",
    "        return serialize_surface(id, surface_set, surface_mask)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord_chunk(serialized_examples, output_path):\n",
    "    with tf.io.TFRecordWriter(str(output_path)) as writer:\n",
    "        for ex in serialized_examples:\n",
    "            if ex:\n",
    "                writer.write(ex)\n",
    "\n",
    "def datasets_to_tfrecords(directory: Path, output_surface_dir: Path,\n",
    "                               chunk_size=10000, num_workers=64):\n",
    "    files = list(directory.glob(\"*.json\"))\n",
    "    total_files = len(files)\n",
    "    output_surface_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i in range(0, total_files, chunk_size):\n",
    "        chunk_files = files[i:i + chunk_size]\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            serialized_examples = list(tqdm(\n",
    "                executor.map(process_surface, chunk_files),\n",
    "                total=len(chunk_files),\n",
    "                desc=f\"Chunk {i//chunk_size:03d}\"\n",
    "            ))\n",
    "\n",
    "        serialized_surfaces = [ex for ex in serialized_examples if ex is not None]\n",
    "\n",
    "        output_surface_path = output_surface_dir / f\"surfaces_chunk_{i//chunk_size:03d}.tfrecord\"\n",
    "\n",
    "        write_tfrecord_chunk(serialized_surfaces, output_surface_path)\n",
    "        print(f\"✅ Saved {len(serialized_surfaces)} surface samples to {output_surface_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e823473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 000: 100%|██████████| 3000/3000 [15:56<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 3000 surface samples to surface_tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_to_tfrecords(directory=data_dir, output_surface_dir=output_surface_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFCoil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
